#!/usr/bin/env python3
"""
MD Simulation Fingerprint Models.

@author: Benjamin Shields 
@email: benjamin.shields@bms.com
"""

############################################################################## Imports

import logging
import pandas as pd
from sklearn.preprocessing import PolynomialFeatures
from mdml import model, cli, plot
from mdml.model import leave_one_out_train

############################################################################## Methods

logger = logging.getLogger(__name__)

MODELS = {
    'ridge':model.RidgeRegression,
    'lasso':model.LassoRegression,
    'elastic_net':model.ElasticNetRegression,
    'random_forest':model.RandomForestRegression
}

############################################################################## Setup

def get_parser():
    description = """Train regression models and evaluate performance using
    leave-one-out cross-validation."""
    parser, groups = cli.parser(description, add_computation=True)
    
    # Input/Output Data
    data = parser.add_argument_group("DATA")
    data.add_argument(
        '-csv',
        type=str,
        default=None,
        help="Path to CSV containing features, IDs, and target (optional).",
        required=True
    )
    data.add_argument(
        '-target_col',
        type=str,
        default=None,
        help="Name of target column in training data CSV.",
        required=True
    )
    data.add_argument(
        '-id_col',
        type=str,
        default=None,
        help="Name of compound ID column.",
        required=True
    )
    data.add_argument(
        '-drop_col',
        nargs='+',
        type=str,
        default=[],
        help="Columns that should be removed from the training CSV."
    )
    data.add_argument(
        '-group',
        type=str,
        default='mean',
        help="""Grouping method. The options include 'mean', 'min', 'max', and
        'softmax'. Data will be grouped by compound ID (id_col)."""
    )
    
    # Model Details
    model = parser.add_argument_group("MODEL")
    model.add_argument(
        '-model_type',
        type=str,
        default='ridge',
        help="""Regression model type. The options  are 'ridge', 'lasso', 
        'elastic_net', and 'random_forest'."""
    )
    model.add_argument(
        '-poly_features',
        action='store_true',
        help="Include polynomial features (order=2) with interaction terms."
    )
    model.add_argument(
        '-cv',
        type=int,
        default=10,
        help="""Number of cross-validation folds to use in hyperparameter 
        tuning. Specify -1 for leave-one-out."""
    )
    model.add_argument(
        '-optimize',
        action='store_true',
        help="""Run iterative optimization of continuous parameters. This 
        option can be helpful for lasso and ridge regressions."""
    )
    model.add_argument(
        '-model_path',
        type=str,
        default='model.pkl',
        help="""Path to save the model."""
    )
    model.add_argument(
        '-plot_path',
        type=str,
        default='parity',
        help="Path to save parity plot for training/cross-validation."
    )
    model.add_argument(
        '-importance_path',
        type=str,
        default='feature_importance.csv',
        help="Path to save feature importance (e.g., regression weights)."
    )
    model.add_argument(
        '-pred_path',
        type=str,
        default='preds.csv',
        help="Path to save predictions."
    )
    
    return parser


############################################################################## Main

def run(args):
    # Load and preprocess data
    logger.debug(f'Loading data: {args.csv}')
    data = cli.csv_to_dataframe(
        args.csv, 
        target_col=args.target_col, 
        id_col=args.id_col, 
        drop=args.drop_col,
        group_method=args.group, 
        group_by=args.id_col
    )
        
    # Add Polynomial Features
    if args.poly_features:
        logger.debug('Including polynomial features')
        X = data.copy().drop(args.target_col, axis=1)
        poly = PolynomialFeatures(
            degree=2, 
            include_bias=False, 
            interaction_only=False
        )
        X = pd.DataFrame(
            poly.fit_transform(X),
            columns=poly.get_feature_names_out(),
            index=data.index
        )
        X[args.target_col] = data[args.target_col]
        data = X.copy()
        
    # Cross-Validation and Training
    logger.debug('Running LOO-CV')
    model = MODELS.get(args.model_type)(data, args.target_col)
    loo = leave_one_out_train(model, n_jobs=args.nproc, cv=args.cv, iter_opt=args.optimize)
    if args.cv == -1:
        title = f'{args.target_col} LOO-CV'
    else:
        title = 'Cross-Validation'
    rmse, r2 = plot.parity_plot(
        loo.get('preds'),
        loo.get('obs'),
        title=title,
        export_path=args.plot_path + '_cv'
    )
    print(f'CV RMSE = {str(rmse)}')
    print(f'CV R^2 = {str(r2)}')
    
    preds = model.predict(data.drop(args.target_col, axis=1))
    rmse, r2 = plot.parity_plot(
        preds,
        data[args.target_col],
        title=f'{args.target_col} Fit',
        export_path=args.plot_path + '_train'
    )
    print(f'Train RMSE = {str(rmse)}')
    print(f'Train R^2 = {str(r2)}')
    
    # Save model and feature importances
    logger.debug('Saving results')
    importance = model.feature_importance()
    importance.to_csv(args.importance_path, header=False)
    model.poly_features = args.poly_features
    model.__save__(args.model_path)
    pred_col = f'predicted {args.target_col}'
    data[pred_col] = preds
    data.reset_index().to_csv(args.pred_path, index=False)


if __name__ == "__main__":
    parser = get_parser()
    args = parser.parse_args()
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    run(args)


