#!/usr/bin/env python3
"""
MD Simulation Fingerprint Model Predictions
--------------------------------------------------------------
Make predictions using trained MD simulation fingerprint models.

@author: Benjamin Shields 
@email: benjamin.shields@bms.com
"""

############################################################################## Imports

import logging
import os
import pandas as pd
import dill

from mdml import model, cli

############################################################################## Setup

logger = logging.getLogger(__name__)

############################################################################## Interface

def get_parser():
    description = """Make predictions using trained MD simulation fingerprint models."""
    parser, groups = cli.parser(description, add_computation=False)
    
    # Input/Output Data
    data = parser.add_argument_group("DATA")
    data.add_argument(
        'input',
        help="Path to CSV containing features and molecule IDs."
    )
    data.add_argument(
        'output',
        help="Path to save prediction CSV."
    )
    data.add_argument(
        '-model',
        type=str,
        default=None,
        help="Directory containing trained ML model",
        required=True
    )
    data.add_argument(
        '-id_col',
        type=str,
        default=None,
        help="Header of compound ID column.",
        required=True
    )
    data.add_argument(
        '-drop_col',
        nargs='+',
        type=str,
        default=[],
        help="Columns that should be removed from the input feature CSV."
    )
    data.add_argument(
        '-group',
        type=str,
        default=None,
        help="""Grouping method. The options include 'mean', 'min', and 'max'. 
        Data will be grouped by compound ID (id_col)."""
    )
    
    return parser

############################################################################## Main

def main(args):
    # Load and preprocess data
    logger.debug(f'Loading data: {args.input}')
    data = cli.load_data(
        args.input, args.id_col, drop=args.drop_col, aggregation=args.group
    )
    logger.debug(f'Dataset contains {len(data)} entries')
    
    # Load modeling workflow
    logger.debug(f'Loading model: {args.model}')
    workflow = model.load_workflow(os.path.join(args.model, 'model.pkl'))

    # Make predictions
    logger.debug(f'Making predictions: {workflow.target}')
    data[f'Predicted {workflow.target}'] = workflow.predict(data)

    # Save results
    logger.debug(f'Saving results to {args.output}')
    data.to_csv(args.output)
    
    
if __name__ == "__main__":
    parser = get_parser()
    args = parser.parse_args()
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    main(args)


